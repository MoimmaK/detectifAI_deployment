# Video Captioning MongoDB + FAISS Integration

## Overview

The video captioning module has been fully integrated with the DetectifAI pipeline, with the following enhancements:

1. **MongoDB Storage**: Captions are now stored in MongoDB Atlas instead of local SQLite database
2. **FAISS Vector Database**: Caption embeddings are stored in FAISS for semantic search
3. **Pipeline Integration**: Automatically processes keyframes during video upload
4. **Debug Logging**: Prints captions for each keyframe during processing

## Architecture

### Components

1. **mongodb_storage.py**: New storage layer that replaces SQLite with MongoDB
   - Stores caption metadata in `video_captions` collection
   - Stores audit logs in `caption_audit` collection
   - Saves embeddings to FAISS vector store on disk

2. **captioning_service.py**: Updated to use MongoDB storage
   - Accepts `db_manager` parameter for database connection
   - Processes frames and generates captions
   - Creates embeddings for semantic search

3. **video_captioning_integrator.py**: Enhanced integration layer
   - Accepts `db_manager` for MongoDB connection
   - Prints detailed debug information for each caption
   - Integrates with main pipeline

4. **main_pipeline.py**: Updated to include video captioning step
   - Step 3c: Video Captioning (after object detection and behavior analysis)
   - Passes `db_manager` to pipeline components

5. **database_video_service.py**: Enhanced with captioning support
   - Step 4.6: Video Captioning in processing flow
   - Updates video metadata with caption counts

## MongoDB Schema

### video_captions Collection

```javascript
{
  "caption_id": "uuid-string",
  "video_id": "video_001",
  "frame_id": "frame_000123",
  "timestamp": "2026-02-06T10:30:00",
  "raw_caption": "a person walking on the street",
  "sanitized_caption": "individual moving along pathway",
  "created_at": "2026-02-06T10:30:05"
}
```

**Indexes:**
- `caption_id` (unique)
- `video_id`
- `frame_id`
- `timestamp`

### caption_audit Collection

```javascript
{
  "raw_caption": "original caption text",
  "sanitized_caption": "sanitized version",
  "rejection_reason": "reason for rejection",
  "created_at": "2026-02-06T10:30:00"
}
```

## FAISS Vector Store

Embeddings are stored in the file system:
- **Location**: `./video_captioning_store/`
- **Files**:
  - `caption_embeddings.pkl`: Pickled numpy arrays of embeddings
  - `caption_metadata.json`: Metadata linking embeddings to captions

## Configuration

Enable video captioning in your config:

```python
from config import get_security_focused_config

config = get_security_focused_config()
config.enable_video_captioning = True
config.captioning_device = "cpu"  # or "cuda" for GPU
config.captioning_batch_size = 4
config.captioning_vector_db_path = "./video_captioning_store"
```

## Usage

### 1. Automatic Processing (via API)

When uploading a video through the API, captioning happens automatically:

```bash
curl -X POST http://localhost:5000/api/v2/video/upload \
  -F "video=@test_video.mp4" \
  -F "user_id=user123"
```

### 2. Manual Processing (Python)

```python
from config import get_security_focused_config
from main_pipeline import CompleteVideoProcessingPipeline
from database.config import DatabaseManager

# Initialize database manager
db_manager = DatabaseManager()

# Configure with captioning enabled
config = get_security_focused_config()
config.enable_video_captioning = True

# Initialize pipeline with db_manager
pipeline = CompleteVideoProcessingPipeline(config, db_manager=db_manager)

# Process video
results = pipeline.process_video_complete("video.mp4")

# Check captioning results
print(f"Total captions: {results['outputs']['total_captions']}")
```

### 3. Search Captions

```python
from video_captioning_integrator import VideoCaptioningIntegrator
from database.config import DatabaseManager

db_manager = DatabaseManager()
captioning = VideoCaptioningIntegrator(config, db_manager=db_manager)

# Semantic search
results = captioning.search_captions(
    query="person walking",
    video_id="video_001",
    top_k=5
)

for result in results:
    print(f"Caption: {result['sanitized_caption']}")
    print(f"Similarity: {result['similarity']:.4f}")
```

### 4. Get Video Captions

```python
# Get all captions for a video
captions = captioning.get_video_captions("video_001")

for caption in captions:
    print(f"{caption['timestamp']}: {caption['sanitized_caption']}")
```

## Debug Output

When processing videos, you'll see detailed debug output:

```
================================================================================
üé¨ VIDEO CAPTIONING RESULTS - KEYFRAME CAPTIONS
================================================================================

üì∏ Keyframe #1 - frame_000001
   ‚è±Ô∏è  Timestamp: 2026-02-06 10:30:00
   üî§ Raw Caption: a person walking on the street
   ‚ú® Sanitized Caption: individual moving along pathway
   üÜî Caption ID: abc123-def456

============================================================
üì∏ Keyframe #1: frame_000001
‚è±Ô∏è  Time: 2026-02-06 10:30:00
üî§ Caption: individual moving along pathway
============================================================

‚úÖ Video captioning complete: 150 captions generated and saved to MongoDB
üíæ Embeddings saved to FAISS vector database
```

## Testing

Run the integration test:

```bash
cd backend
python test_video_captioning_integration.py
```

This will:
1. Test MongoDB connection
2. Initialize video captioning
3. Process test frames
4. Generate captions
5. Test semantic search
6. Display statistics

## Features

### 1. MongoDB Integration
- ‚úÖ Captions stored in MongoDB Atlas
- ‚úÖ Automatic indexing for fast queries
- ‚úÖ Audit logging for rejected captions
- ‚úÖ Scalable cloud storage

### 2. FAISS Vector Search
- ‚úÖ Semantic similarity search
- ‚úÖ Fast nearest neighbor queries
- ‚úÖ Persistent storage on disk
- ‚úÖ Efficient embedding management

### 3. Pipeline Integration
- ‚úÖ Automatic processing during video upload
- ‚úÖ Integrated with object detection and behavior analysis
- ‚úÖ Progress tracking and status updates
- ‚úÖ Error handling and recovery

### 4. Debug Features
- ‚úÖ Detailed logging for each caption
- ‚úÖ Console output for immediate visibility
- ‚úÖ Processing statistics
- ‚úÖ Error tracking

## Performance

- **Caption Generation**: ~0.5-1s per frame (CPU)
- **Embedding Generation**: ~0.1s per caption
- **MongoDB Storage**: ~10ms per caption
- **FAISS Search**: <1ms for top-k queries

## Troubleshooting

### Issue: MongoDB Connection Failed

**Solution**: Check your MongoDB URI in `.env`:
```bash
MONGO_URI=mongodb+srv://user:pass@cluster.mongodb.net/detectifai
```

### Issue: FAISS Directory Not Found

**Solution**: The directory is created automatically. Ensure write permissions:
```bash
mkdir -p video_captioning_store
chmod 755 video_captioning_store
```

### Issue: Captions Not Appearing

**Solution**: Verify captioning is enabled:
```python
config.enable_video_captioning = True
```

### Issue: Out of Memory

**Solution**: Reduce batch size:
```python
config.captioning_batch_size = 2  # Reduce from 4
```

## API Endpoints

### Get Video Captions

```bash
GET /api/video/{video_id}/captions
```

### Search Captions

```bash
POST /api/captions/search
{
  "query": "person walking",
  "video_id": "video_001",
  "top_k": 5
}
```

### Get Caption Statistics

```bash
GET /api/captions/statistics
```

## Future Enhancements

- [ ] Real-time caption streaming
- [ ] Multi-language support
- [ ] Custom caption templates
- [ ] Advanced filtering options
- [ ] Caption export (JSON, CSV, SRT)
- [ ] Integration with NLP search module

## Dependencies

```
pymongo>=4.0.0
sentence-transformers>=2.2.0
transformers>=4.30.0
torch>=2.0.0
Pillow>=9.0.0
numpy>=1.21.0
```

## License

Part of DetectifAI surveillance system.
